{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from google sheets: Saved, Credentials submitted\n",
      "Google sheets data = Data Frame\n",
      "Data Base access granted, SQL connection completed\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import pandas as pd\n",
    "import mysql.connector as sql\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Google sheet Reading\n",
    "\n",
    "SHEET_ID = '1ISR4awJLze6OZdZH9YJ6ilTBNXsM-qE6vLz2sQnY6_o'\n",
    "SHEET_NAME = 'all_Data'\n",
    "SHEET_NAME_PROD = 'production_data'\n",
    "SHEET_NAME_ROST = 'roster_data'\n",
    "\n",
    "gc = gspread.service_account('Andres_key.json')\n",
    "spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "\n",
    "worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "worksheet_prod = spreadsheet.worksheet(SHEET_NAME_PROD)\n",
    "worksheet_roster = spreadsheet.worksheet(SHEET_NAME_ROST)\n",
    "\n",
    "rows = worksheet.get_all_records()\n",
    "rows_prod = worksheet_prod.get_all_records()\n",
    "rows_roster = worksheet_roster.get_all_records()\n",
    "print('Data from google sheets: Saved, Credentials submitted')\n",
    "\n",
    "#Panda transform\n",
    "df = pd.DataFrame(rows)\n",
    "df_prod = pd.DataFrame(rows_prod)\n",
    "df_roster = pd.DataFrame(rows_roster)\n",
    "print('Google sheets data = Data Frame')\n",
    "\n",
    "#SQL connection\n",
    "mydb = sql.connect(\n",
    "    host = 'localhost',\n",
    "    user = 'root',\n",
    "    password = '1234',\n",
    "    database = 'assesment'\n",
    ")\n",
    "mycursor = mydb.cursor()\n",
    "print('Data Base access granted, SQL connection completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            int64\n",
      "full_name    object\n",
      "email        object\n",
      "country      object\n",
      "team_lead    object\n",
      "status       object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"07/06/2022\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 695. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(df_roster\u001b[39m.\u001b[39mdtypes)\n\u001b[0;32m      4\u001b[0m \u001b[39m#Casting to numeric\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      6\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcpc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mcpc\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m$]\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m      7\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39minteractions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39minteractions\u001b[39m\u001b[39m'\u001b[39m], errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1050\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1049\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1050\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   1051\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   1052\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:453\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39;49m, exact, errors)\n\u001b[0;32m    455\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[39m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:484\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    474\u001b[0m     arg,\n\u001b[0;32m    475\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     errors: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    480\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[0;32m    481\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     result, timezones \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors, utc\u001b[39m=\u001b[39;49mutc)\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m tz \u001b[39min\u001b[39;00m timezones):\n\u001b[0;32m    486\u001b[0m         \u001b[39mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:530\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:351\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"07/06/2022\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 695. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "#Data Casting\n",
    "print(df_roster.dtypes)\n",
    "\n",
    "#Casting to numeric\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['cpc'] = df['cpc'].str.replace('[\\$]','',regex=True).astype(float)\n",
    "df['interactions'] = pd.to_numeric(df['interactions'], errors='coerce')\n",
    "df['csat'] = pd.to_numeric(df['csat'], errors='coerce')\n",
    "\n",
    "df_prod['date'] = pd.to_datetime(df_prod['date'])\n",
    "df_prod['cpc'] = df_prod['cpc'].str.replace('[\\$]','',regex=True).astype(float)\n",
    "df_prod['interactions'] = pd.to_numeric(df_prod['interactions'], errors='coerce')\n",
    "df_prod['csat'] = pd.to_numeric(df_prod['csat'], errors='coerce')\n",
    "\n",
    "\n",
    "print('Data Casted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data succesfully copied\n",
      "Null information removed from the original data\n",
      "date             0\n",
      "interactions     0\n",
      "channel          0\n",
      "csat             0\n",
      "service_level    0\n",
      "cpc              0\n",
      "id               0\n",
      "full_name        0\n",
      "email            0\n",
      "country          0\n",
      "team_lead        0\n",
      "status           0\n",
      "coaching         0\n",
      "work_hours       0\n",
      "abs_hours        0\n",
      "dtype: int64\n",
      "date             0\n",
      "interactions     0\n",
      "channel          0\n",
      "csat             0\n",
      "service_level    0\n",
      "cpc              0\n",
      "id               0\n",
      "full_name        0\n",
      "email            0\n",
      "country          0\n",
      "team_lead        0\n",
      "status           0\n",
      "coaching         0\n",
      "work_hours       0\n",
      "abs_hours        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Deleting null data\n",
    "df_copy = df.copy() #saving a copy\n",
    "print('Data succesfully copied')\n",
    "\n",
    "df_notnull = df.dropna(how= 'any') #null data removed\n",
    "df_notnull_prod = df_prod.dropna(how = 'any') #null data removed\n",
    "print('Null information removed from the original data')\n",
    "\n",
    "print(df_notnull.isnull().sum())\n",
    "print(df_copy.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully loaded on sheets\n",
      "DataFrame inserted into MySQL table successfully\n",
      "Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Data Google sheet Loading\n",
    "\n",
    "# Worksheet loading\n",
    "target_worksheet_name = SHEET_NAME\n",
    "target_worksheet = spreadsheet.worksheet(target_worksheet_name)\n",
    "set_with_dataframe(target_worksheet, df_notnull)\n",
    "\n",
    "print('DataFrame successfully loaded on sheets')\n",
    "\n",
    "# Table Loading\n",
    "engine = create_engine('mysql+mysqlconnector://root:1234@localhost/assesment')\n",
    "\n",
    "table_name = 'assesment_db'\n",
    "table_name_prod = 'prod_db'\n",
    "table_name_roster = 'roster_db'\n",
    "\n",
    "df_notnull.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "df_notnull_prod.to_sql(table_name_prod,con=engine, if_exists='replace', index=False)\n",
    "df_roster.to_sql(table_name_roster,con=engine,if_exists='replace',index=False)\n",
    "print('DataFrame inserted into MySQL table successfully')\n",
    "\n",
    "# Close the database connection\n",
    "if mydb and mydb.is_connected():\n",
    "    mydb.close()\n",
    "    print('Database connection closed')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
